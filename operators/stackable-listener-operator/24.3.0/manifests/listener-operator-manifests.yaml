---
apiVersion: v1
kind: ConfigMap
metadata:
  name: listener-operator-deployer-manifests
data:
  deploy.sh: |
    #!/bin/env bash
    set -euox pipefail

    echo 'Deploying listener-operator manifests'

    export LISTENER_OPERATOR_DEPLOYER_DEPLOYMENT_UID=$(kubectl get deployment listener-operator-deployer -o go-template='{{.metadata.uid}}')
    export LISTENER_OPERATOR_CLUSTERROLE_NAME=$(kubectl get clusterrole -l olm.owner=listener-operator.v24.3.0,olm.owner.kind=ClusterServiceVersion -o name | head -n 1 | sed 's/^.*\///')
    export LISTENER_OPERATOR_CLUSTERROLE_UID=$(kubectl get clusterrole $LISTENER_OPERATOR_CLUSTERROLE_NAME -o go-template='{{.metadata.uid}}')

    for file in /manifests/*.yaml; do
      echo Deploying $file
      cat $file | envsubst | ./kubectl apply --wait -f -
    done

    echo 'Successfully deployed listener-operator manifests'

    sleep infinity
  csidriver.yaml: |
    ---
    apiVersion: storage.k8s.io/v1
    kind: CSIDriver
    metadata:
      name: listeners.stackable.tech
      ownerReferences:
        # We have to use a clusterScope object as an owner of another clusterScope object
        - apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          name: "${LISTENER_OPERATOR_CLUSTERROLE_NAME}"
          uid: "${LISTENER_OPERATOR_CLUSTERROLE_UID}"
    spec:
      attachRequired: false
      podInfoOnMount: true
      fsGroupPolicy: File
      volumeLifecycleModes:
        - Ephemeral
        - Persistent
  storageclass.yaml: |
    ---
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: listeners.stackable.tech
      ownerReferences:
        - apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          name: "${LISTENER_OPERATOR_CLUSTERROLE_NAME}"
          uid: "${LISTENER_OPERATOR_CLUSTERROLE_UID}"
    provisioner: listeners.stackable.tech
    volumeBindingMode: WaitForFirstConsumer
  node-daemonset.yaml: |
    ---
    # Source: listener-operator/templates/node-daemonset.yaml
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: listener-operator-node-daemonset
      labels:
        app.kubernetes.io/name: listener-operator
        app.kubernetes.io/instance: listener-operator
        stackable.tech/vendor: Stackable
        app.kubernetes.io/version: "24.3.0"
      ownerReferences:
        - apiVersion: apps/v1
          kind: Deployment
          name: listener-operator-deployer
          uid: "${LISTENER_OPERATOR_DEPLOYER_DEPLOYMENT_UID}"
    spec:
      selector:
        matchLabels:
          app.kubernetes.io/role: node
          app.kubernetes.io/name: listener-operator
          app.kubernetes.io/instance: listener-operator
          stackable.tech/vendor: Stackable
      template:
        metadata:
          labels:
            app.kubernetes.io/role: node
            app.kubernetes.io/name: listener-operator
            app.kubernetes.io/instance: listener-operator
            stackable.tech/vendor: Stackable
        spec:
          serviceAccountName: listener-operator-serviceaccount
          securityContext: {}
          containers:
            - name: listener-operator
              securityContext:
                runAsUser: 0
                seLinuxOptions:
                  type: spc_t
              image: "quay.io/stackable/listener-operator@sha256:89fa54f10fece956413a9e51c16832afdc856d1d34cdcc57195139a82a3174a7"
              imagePullPolicy: IfNotPresent
              resources:
                limits:
                  cpu: 100m
                  memory: 128Mi
                requests:
                  cpu: 100m
                  memory: 128Mi
              args:
                - run
                - node
              env:
                - name: CSI_ENDPOINT
                  value: /csi/csi.sock
                - name: NODE_NAME
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: spec.nodeName
              volumeMounts:
                - name: csi
                  mountPath: /csi
                - name: mountpoint
                  mountPath: /var/lib/kubelet/pods
            - name: node-driver-registrar
              image: "quay.io/stackable/sig-storage/csi-node-driver-registrar@sha256:fd3af885aee57b6d0ee64db646e5edcba0e3bed8839aaf3584cce037b0f16c66"
              imagePullPolicy: IfNotPresent
              resources:
                limits:
                  cpu: 100m
                  memory: 128Mi
                requests:
                  cpu: 100m
                  memory: 128Mi
              args:
                - --csi-address=/csi/csi.sock
                - --kubelet-registration-path=/var/lib/kubelet/plugins/listeners.stackable.tech/csi.sock
              volumeMounts:
                - name: registration-sock
                  mountPath: /registration
                - name: csi
                  mountPath: /csi
          volumes:
            - name: registration-sock
              hostPath:
                # node-driver-registrar appends a driver-unique filename to this path to avoid conflicts
                # see https://github.com/stackabletech/secret-operator/issues/229 for why this path should not be too long
                path: /var/lib/kubelet/plugins_registry
            - name: csi
              hostPath:
                path: /var/lib/kubelet/plugins/listeners.stackable.tech/
            - name: mountpoint
              hostPath:
                path: /var/lib/kubelet/pods/
  cluster-internal.yaml: |
    ---
    apiVersion: listeners.stackable.tech/v1alpha1
    kind: ListenerClass
    metadata:
      name: cluster-internal
      ownerReferences:
        - apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          name: "${LISTENER_OPERATOR_CLUSTERROLE_NAME}"
          uid: "${LISTENER_OPERATOR_CLUSTERROLE_UID}"
    spec:
      serviceType: ClusterIP
  external-stable.yaml: |
    ---
    # Source: listener-operator/templates/listener-classes.yaml
    apiVersion: listeners.stackable.tech/v1alpha1
    kind: ListenerClass
    metadata:
      name: external-stable
      ownerReferences:
        - apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          name: "${LISTENER_OPERATOR_CLUSTERROLE_NAME}"
          uid: "${LISTENER_OPERATOR_CLUSTERROLE_UID}"
    spec:
      # To support environments that don't have LoadBalancer support, we fall back to using NodePort Services for "stable addresses".
      # To ensure that these addresses are actually stable, the Listener Operator will "bind" such Listeners to only run on the Node that
      # they were originally scheduled to (as controlled by the lifetime of the PersistentVolume). The downside here is that we prevent Kubernetes
      # from migrating that workload to a different Node (such as if it goes down).
      #
      # This is useful for cloud environments with no Cloud Controller Manager (or one which doesn't support LoadBalancers),
      # or on-premise environments that don't support external LoadBalancer peering (such as Calico (https://docs.tigera.io/calico/latest/networking/configuring/advertise-service-ips)
      # or MetalLB (https://metallb.org/)).
      serviceType: NodePort
  external-unstable.yaml: |
    ---
    # Source: listener-operator/templates/listener-classes.yaml
    apiVersion: listeners.stackable.tech/v1alpha1
    kind: ListenerClass
    metadata:
      name: external-unstable
      ownerReferences:
        - apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          name: "${LISTENER_OPERATOR_CLUSTERROLE_NAME}"
          uid: "${LISTENER_OPERATOR_CLUSTERROLE_UID}"
    spec:
      serviceType: NodePort
